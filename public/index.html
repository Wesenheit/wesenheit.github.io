<!DOCTYPE html>
<html>
	<head lang="en">
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Wesenheit | Home </title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="" />
	<meta property="og:image" content=""/>
	<link rel="alternate" type="application/rss+xml" href="https://wesenheit.github.io/index.xml" title="Wesenheit" />
	<meta property="og:url" content="https://wesenheit.github.io/">
  <meta property="og:site_name" content="Wesenheit">
  <meta property="og:title" content="Wesenheit">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="website">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Wesenheit">

        <link href="https://wesenheit.github.io/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css" rel="stylesheet">
	

	
	<link rel="stylesheet" type="text/css" media="screen" href="https://wesenheit.github.io/css/main.6a0f23ea50fd34b46fee262a5a68e17d458c51a2bc99ba1ba018065de6b180c3.css" />
		<link id="darkModeStyle" rel="stylesheet" type="text/css" href="https://wesenheit.github.io/css/dark.50b57e12d401420df23965fed157368aba37b76df0ecefd0b1ecd4da664f01a0.css"  disabled /><script type="text/javascript"
		src="https://wesenheit.github.io/js/MathJax.js"></script>
		
		<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [['$','$'], ['\\(','\\)']],
				displayMath: [['$$','$$'], ['\[','\]']],
				processEscapes: true,
				processEnvironments: true,
				skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
				TeX: { equationNumbers: { autoNumber: "AMS" },
						 extensions: ["AMSmath.js", "AMSsymbols.js"] }
			}
		});
		</script><link rel="stylesheet" href="https://wesenheit.github.io/katex/katex.min.css ">
		<script defer src="https://wesenheit.github.io/katex/katex.min.js"></script>
		<script defer src="https://wesenheit.github.io/katex/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
		
		<script>
			document.addEventListener("DOMContentLoaded", function() {
					renderMathInElement(document.body, {
							delimiters: [
									{left: "$$", right: "$$", display: true},
									{left: "$", right: "$", display: false}
							]
					});
			});
		</script>
</head>

	<body>
		<div class="content">
			<header>
	<div class="main">
		<a href="https://wesenheit.github.io/">Wesenheit</a>
	</div>
	<nav>
		
		<a href="/">Home</a>
		
		<a href="/posts">All posts</a>
		
		<a href="/about">About</a>
		
		<a href="/tags">Tags</a>
		
		| <span id="dark-mode-toggle" onclick="toggleTheme()"><svg class="feather">
   <use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#sun" />
</svg></span>
		<script src="https://wesenheit.github.io/js/themetoggle.js"></script>
		
	</nav>
</header>



<link rel="stylesheet" href="/css/custom.css">

			
			<main class="list">
				<div class="site-description"><p>Applying math to solve different problems.</p></div>
				
				
				
				<section class="list-item">
					<h1 class="title"><a href="/posts/2025-03-01-abc-trams/">Approximate Bayesian Computation with Wrocław trams</a></h1>
					<time>Mar 1, 2025</time>
					<br><div class="description">
	
	<h2 id="introduction">Introduction</h2>
<p>Recently, I presented some results from the field of Simulation-Based Inference at the Statistical Journal Club at the Astronomical Observatory. While modern neural networks allow the creation of some
incredible models that allow for the Likelihood Free Inference (LFI), there are also some more old-school examples from the field of statistics. Those were usually labeled
as the Approximate Bayesian Computation (ABC) methods. Here, I would like to write something about the classical implementation and apply it to one of my favorite
problems known as the German tanks problem (although here there will be trams).</p>&hellip;
	
</div>
					<a class="readmore" href="/posts/2025-03-01-abc-trams/">Read more ⟶</a>
				</section>
				
				<section class="list-item">
					<h1 class="title"><a href="/posts/2023-03-19-gmvae-clustering-applied-to-rna-sequencing/">GMVAE clustering applied to RNA sequencing</a></h1>
					<time>Mar 19, 2023</time>
					<br><div class="description">
	
	<h2 id="introduction">Introduction</h2>
<p>One of many classical tasks of machine learning is clustering, based on the data one would like to distinguish some clusters.
There are many classical approaches to clustering, the most notable ones include: K-means, GMM (Gaussian Mixture Model) trained with the EM algorithm, and DBSCAN.
While each of those algorithms is widely used in research and industry,
all of them try to cluster the data using its original representation and mostly fail in the case of hidden similarity between observations.\
In this post, I present a GMM+VAE deep learning architecture, which will be used to cluster the data based on a learned embedding of the data.
The clustering model is based on <a href="https://arxiv.org/abs/1611.02648">this paper</a>, while application to RNA sequencing data is based on the work that I performed during my studies at the Warsaw University.
The original project with a solution can be found in a related <a href="https://github.com/Wesenheit/SAD2-22W/tree/main/Project1">GitHub repository</a>.
The dataset used in the study was taken from the <a href="https://openproblems.bio/competitions/neurips_2021/">NeuroIPS 2021</a> competition. In this blog, we will tackle the joint
embedding part of the competition. We will try to embed biological information in an unsupervised manner and at the same time reduce the impact of batch effect on
the model performance.</p>&hellip;
	
</div>
					<a class="readmore" href="/posts/2023-03-19-gmvae-clustering-applied-to-rna-sequencing/">Read more ⟶</a>
				</section>
				
				<section class="list-item">
					<h1 class="title"><a href="/posts/2023-02-02-lstm-tolkien/">LSTM vs Tolkien</a></h1>
					<time>Feb 2, 2023</time>
					<br><div class="description">
	
	<h1 id="introduction">Introduction</h1>
<p>This notebook is greatly inspired by <a href="https://gbnegrini.com/post/tolkien-character-or-prescription-drug-neural-networks/">this notebook</a> by G. Negrini. Please check out his website, as he make really good content.
In original notebook, the Keras library was used. This approach is based on duo Jax + <a href="https://dm-haiku.readthedocs.io/en/latest/">Haiku</a> from DeepMind.
We will try to distinguish between drug names and Tolkien characters
using simple LSTM model, surprisingly it isn&rsquo;t as easy as one can think. If you want to challenge yourself, here is popular website with <a href="https://antidepressantsortolkien.vercel.app/">great quiz</a>.</p>&hellip;
	
</div>
					<a class="readmore" href="/posts/2023-02-02-lstm-tolkien/">Read more ⟶</a>
				</section>
				
				


			</main>
			<footer>
  <div style="display:flex"><a class="soc" href="https://github.com/wesenheit" rel="me" title="GitHub"><svg class="feather">
   <use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#github" />
</svg></a><a class="border"></a></div>
  <div class="footer-info">
    2025  <a
      href="https://github.com/athul/archie">Archie Theme</a> | Built with <a href="https://gohugo.io">Hugo</a>
  </div>
</footer>




		</div>
		
	</body>
</html>
